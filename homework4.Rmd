---
title: "PSTAT 115 Homework 5"
author: "Nivi Lakshminarayanan, Celeste Herrera"
date: "__Due on November 29, 2020 at 11:59 pm__"
output: pdf_document
urlcolor: blue

---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo=TRUE, 
                      cache=FALSE, 
                      fig.width=5, 
                      fig.height=5,
                      fig.align='center')
r = function(x, digits=2){ round(x, digits=digits) }
indent1 = '    '      
indent2 = paste(rep(indent1, 2), collapse='')
library(tidyverse)
library(reshape2)
library(magrittr)
library(StanHeaders)
library(rstan)
```

__Note:__ If you are working with a partner, please submit only one homework per group with both names and whether you are taking the course for graduate credit or not.  Submit your Rmarkdown (.Rmd) and the compiled pdf on Gauchospace.
 
 

### Problem 1. Frequentist Coverage of The Bayesian Posterior Interval. 

In quiz 1 we explored the importance and difficulty of well-calibrated prior distributions by examining the calibration of subjective intervals.  Suppose that $y_1,..,y_n$ is an IID sample from a $Normal(\mu, 1)$.  We wish to estimate $\mu$.  

**1a.** For Bayesian inference, we will assume the prior distribution $\mu \sim Normal(0,\frac{1}{\kappa_0})$ for all parts below. Remember, from lecture that we can interpret $\kappa_0$ as the pseudo-number of prior observations with sample mean $\mu_0 = 0$.  State the posterior distribution of $\mu$ given $y_1,..,y_n$. Report the lower and upper bounds of the $95\%$ quantile-based posterior credible interval for $\mu$, using the fact that for a normal distribution with standard deviation $\sigma$, approximately $95\%$ of the mass is between $\pm 1.96\sigma$. \newline

We know that the posterior must be in the format
$\text{Posterior} \sim \text{N} (\mu_{n}, \sigma^2_n)$. 

We know that the posterior variance $$\sigma^2_n = \frac{\sigma^2}{\kappa_0 + n}$$

Now we must rewrite our posterior mean $\mu_n$. We know $\mu_n = (1-w)\mu_0 + w\bar{y}$ where $w = \displaystyle\frac{\frac{n}{\sigma^2}}{\frac{\kappa_0}{\sigma^2} + \frac{n}{\sigma^2}}$ and $(1-w) = \displaystyle\frac{\kappa_0}{\kappa_0 + n}$. So, we can rewrite $\mu_n$ to be

$$\mu_n = (1-w)\mu_0 + w\bar{y}$$

$$= \left(\displaystyle\frac{\kappa_0}{\kappa_0 + n}\right)\mu_0 + \left(\displaystyle\frac{\frac{n}{\sigma^2}}{\frac{\kappa_0}{\sigma^2} + \frac{n}{\sigma^2}}\right)\bar{y}$$

$$=\displaystyle\frac{\kappa_0\mu_0}{\kappa_0 + n} + \frac{n\bar{y}}{\kappa_0 + n}$$

$$= \displaystyle\frac{\kappa_0\mu_0+ n\bar{y}}{\kappa_0 + n}$$

Since $\mu_0 = 0$, we can simplify this to be

$$\mu_n = \displaystyle\frac{ n\bar{y}}{\kappa_0 + n}$$

Therefore we will have a posterior distribution $$P(\mu|y_1,...,y_n, \sigma^2) \sim N\left(\frac{ n\bar{y}}{\kappa_0 + n}, \frac{1}{\kappa_0 + n}\right)$$ 

Now we must solve for the lower and upper bounds of the 95% quantile-based posterior credible interval for $\mu$. We are given that for a normal distribution with standard deviation $\sigma$, approximately 95% of the mass is between $\pm1.96\sigma$. We stated earlier that $\sigma^2_n = \frac{\sigma^2}{\kappa_0 + n}$ where $\sigma^2$ = 1. 

So, we can say that the lower bound of the 95% Credible Interval is $$\mu_n - 1.96\sqrt{\sigma^2} = \displaystyle\frac{n\bar{y}}{\kappa_0 + n} - 1.96\sqrt{\frac{1}{\kappa_0 + n}}$$. 

We can say that the upper bound of the 95% Credible Interval is $$\mu_n + 1.96\sqrt{\sigma^2} = \displaystyle\frac{n\bar{y}}{\kappa_0 + n} + 1.96\sqrt{\frac{1}{\kappa_0 + n}}$$

The length of the interval is

$$\left(\displaystyle\frac{n\bar{y}}{\kappa_0 + n} + 1.96\sqrt{\frac{1}{\kappa_0 + n}}\right) - \left(\displaystyle\frac{n\bar{y}}{\kappa_0 + n} - 1.96\sqrt{\frac{1}{\kappa_0 + n}}\right)$$

$$ = 1.96\sqrt{\frac{1}{\kappa_0 + n}} + 1.96\sqrt{\frac{1}{\kappa_0 + n}} = 3.92\sqrt{\frac{1}{\kappa_0 + n}}$$

**1b**. Plot the length of the posterior credible interval as a function of $\kappa_0$, for $\kappa_0 = 1, 2, ..., 25$ assuming $n=10$.  Report how this prior parameter effects the length of the posterior interval and why this makes intuitive sense.

```{r}
set.seed(100)
mu0 = 0
sigma <- 1
n<- 10
kappa_0<- c(1:25)

y <- rnorm(n,mu0,sigma)
ybar<-mean(y)

#posterior parameter
mu_n<- (n * ybar) / (kappa_0 + n)
var <- sigma / (kappa_0 + n)

#interval
lower_bound<- mu_n - (1.96*sqrt(var))
upper_bound<- mu_n + (1.96*sqrt(var))
interval95 <- upper_bound - lower_bound
interval95

plot(x = kappa_0, y=interval95, xlab = "Value of Kappa0", ylab = "Posterior Credible Interval Length", main = "Posterior Credible Interval Length d/t Kappa0 Value", col = "blue")
```

We can see that the prior parameter $\kappa_0$ affects the length of the posterior interval in that the interval length steadily decreases as the value of $\kappa_0$ increases. This makes sense as we saw in part 1(b) that the length of the interval is $3.92\sqrt{\frac{1}{\kappa_0 + n}}$, so as the value of $\kappa_0$ increases, the value of $\frac{1}{\kappa_0 + n}$ decreases, making the interval length as a whole decrease too.


**1c**. Now we will evaluate the _frequentist coverage_ of the posterior credible interval on simulated data.  Generate 1000 data sets where the true value of $\mu=0$ and $n=10$.  For each dataset, compute the posterior $95\%$ interval endpoints (from the previous part) and see if it the interval covers the true value of $\mu = 0$.  Compute the frequentist coverage as the fraction of these 1000 posterior 95\% credible intervals that contain $\mu=0$.  Do this for each value of $\kappa_0 = 1, 2, ..., 25$.  Plot the coverage as a function of $\kappa_0$.

```{r}
set.seed(100)

sigma <- 1
n <- 10
mu <- 0

count <- matrix(0, ncol=1, nrow = 25)
coverage = rep(0,25)

for (k in 1:25) {
  for (i in 1:1000) {
    y = rnorm(n,mu,sigma)
    mu_n = (n * mean(y)) / (k + n)
    var = sigma / (k + n)
    lower_bound <- mu_n - (1.96 * sqrt(var))
    upper_bound <- mu_n + (1.96 * sqrt(var))
    if (upper_bound > 0 & lower_bound < 0) {
      count[k] = count[k] + 1
    }
  }
  coverage[k] <- count[k] / 1000

}

plot(kappa_0, coverage, col="purple", xlab="Value of Kappa",
     ylab="Coverage Percentage",
     main="Freq. Coverage of Posterior CI/Kappa(n), mu0 = 0", pch=19)
abline(h=.95)
```
    
**1d.** Repeat the 1c but now generate data assuming the true $\mu=1$.

```{r}
set.seed(100)

sigma <- 1
n <- 10
mu <- 1

count <- matrix(0, ncol=1, nrow = 25)
coverage = rep(0,25)

for (k in 1:25) {
  for (i in 1:1000) {
    y = rnorm(n,mu,sigma)
    mu_n = (n * mean(y)) / (k + n)
    var = sigma / (k + n)
    lower_bound <- mu_n - (1.96 * sqrt(var))
    upper_bound <- mu_n + (1.96 * sqrt(var))
    if (between(1, lower_bound, upper_bound) == TRUE) {
      count[k] = count[k] + 1
    }
  }
  coverage[k] <- count[k] / 1000
}


plot(kappa_0, coverage, col=rainbow(25), xlab="Value of Kappa",
     ylab="Coverage Percentage",
     main="Freq. Coverage of Posterior CI/Kappa(n), mu0 = 1", pch=19)
abline(h=.95)

```

**1e**. Explain the differences between the coverage plots when the true $\mu$ = 0 and the true $\mu = 1$.  For what values of $\kappa_0$ do you see closer to nominal coverage (i.e. 95\%)?  For what values does your posterior interval tend to overcover (the interval covers the true value more than 95\% of the time)? Undercover (the interval covers the true value less than 95\% of the time)?  Why does this make sense?

In the plot for 1c where we set the true $\mu=0$, our plot reveals that the coverage percent generally increases as $\kappa_0$ gets larger and approaches 25. We have the closest to nominal coverage when $\kappa_0$ = 1, and the coverage generally increases and consistently overcovers as the $\kappa_0$ value increases. This makes sense as in this case, the real value of $\mu = 0$ matches the prior belief that $\mu_0 = 0$. Due to this, the graph for $mu=0$ is increasing and approaches 1 as $\kappa_0$ approaches 25, as we are getting more and more convinced about our prior belief that $\mu_0 = 0$.

In the plot for 1d where we set the true $\mu=1$, our plot reveals that the coverage percent rapidly decreases and approaches 0 as $\kappa_0$ gets larger and approaches 25. We once again have the closest to nominal coverage when $\kappa_0 = 1$, and the coverage generally decreases and consistently undercovers as the $\kappa_0$ value increases from here. This makes sense as in this case, the real value of $\mu=1$ does NOT match the prior belief that $\mu_0 = 0$. Due to this mismatch, it is natural that the coverage fraction would decrease and approach to 0 as $\kappa_0$ approaches 25.

### Bayesian inference for the normal distribution in Stan.

Create a new Stan file by selecting  "Stan file" in the Rstudio menu.  Save it as `IQ_model.stan`.  We will make some basic modifications to the template example in the default Stan file for this problem.  Consider the IQ example used from class.  Scoring on IQ tests is designed to yield a N(100, 15) distribution for the general population.   We observe IQ scores for a sample of 
$n$ individuals from a particular town, $y_1, \ldots y_n \sim N(\mu, \sigma^2)$.  Our goal is to estimate the population mean in the town.  Assume the $p(\mu, \sigma) = p(\mu \mid \sigma)p(\sigma)$, where $p(\mu \mid \sigma)$ is $N(\mu_0, \sigma/\sqrt{\kappa_0})$ and $p(\sigma)$ is Gamma(a, b). Before you administer the IQ test you believe the town is no different than the rest of the population, so you assume a prior mean for $\mu$ of  $\mu_0 = 100$, but you aren't to sure about this a priori and so you set $\kappa_0 = 1$ (the effective number of pseudo-observations). Similarly, a priori you assume $\sigma$ has a mean of 15 (to match the intended standard deviation of the IQ test) and so you decide on setting $a=15$ and $b=1$ (remember, the mean of a Gamma is a/b).  Assume the following IQ scores are observed:

```{r, echo=TRUE, eval=FALSE}
y <- c(70, 85, 111, 111, 115, 120, 123)
n <- length(y)
```

**2a**. Make a scatter plot of the posterior distribution of the median, $\mu$, and the precision, $1/\sigma^2$. Put $\mu$ on the x-axis and $1/\sigma^2$ on the y-axis.  What is the posterior relationship between $\mu$ and $1/\sigma^2$?  Why does this make sense? _Hint:_ review the lecture notes.

```{r}
library(rstan)
set.seed(123)

y <- c(70, 85, 111, 111, 115, 120, 123)
n <- length(y)
a = 15
b = 1
k0 = 1
mu0 = 100
```

```{r stan_samples, dependson="stan_def", cache=TRUE}
set.seed(123)
#compile stan model
stan_model <- stan_model(file="IQ_model.stan")
#fit stan model
stan_fit <- rstan::sampling(stan_model, data = list(N=n,a=a,b=b,mu0=mu0,k0=k0,y=y),refresh=0)
#extract samples
samples <- rstan::extract(stan_fit)
```

```{r}
set.seed(123)
mu_samples <- samples$mu
sigma_samples <- samples$sigma

tibble(Mean = mu_samples, Precision=1/sigma_samples^2) %>%
 ggplot() +
 geom_point(aes(x=Mean, y=Precision)) +
 theme_bw(base_size=16)
```

From the plot above, we can see that we have a small number of values that have high precision and equivalently low posterior variability in $\mu$, since these values have an approximate mean between 100 and 110. We can also see towards the bottom of the graph that there are a large number of values that have low precision and equivently high uncertainty about $\mu$. This makes sense as a higher precision value would naturally be associated with a smaller range of mean values given the definition of precision.

**2b**. You are interested in whether the mean IQ in the town is greater than the mean IQ in the overall population.  Use Stan to find the posterior probability that $\mu$ is greater than 100.

```{r stan_def, cache=TRUE}
y <- c(70, 85, 111, 111, 115, 120, 123)
n <- length(y)

prob_stan = sum((mu_samples > 100) == TRUE) / length(mu_samples)
prob_stan
```

**2c.** You notice that two of the seven scores are significantly lower than the other five.  You think that the normal distribution may not be the most appropriate model, in particular because you believe some people in this town are likely have extreme low and extreme high scores.  One solution to this is to use a model that is more robust to these kinds of outliers.  The [Student's t distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution) and the [Laplace distribution](https://en.wikipedia.org/wiki/Laplace_distribution) are two so called "heavy-tailed distribution" which have higher probabilities of outliers (i.e. observations further from the mean).  Heavy-tailed distributions are useful in modeling because they are more robust to outliers.  Fit the model assuming now that the IQ scores in the town have a Laplace distribution, that is $y_1, \ldots, y_n \sim Laplace(\mu, \sigma)$. Create a copy of the previous stan file, and name it "IQ_laplace_model.stan".  _Hint:_ In the Stan file you can replace `normal` with `double_exponential` in the model section, another name for the Laplce distribution.  Like the normal distribution it has two arguments, $\mu$ and $\sigma$.  Keep the same prior distribution, $p(\mu, \sigma)$ as used in the normal model.  Under the Laplace model, what is the posterior probability that the median IQ in the town is greater than 100?  How does this compare to the probability under the normal model? Why does this make sense?

```{r laplace_stan_samples, dependson="stan_def", cache=TRUE}
set.seed(123)
library(rstan)
y <- c(70, 85, 111, 111, 115, 120, 123)
n <- length(y)

#compile stan model
laplace_stan_model <- stan_model(file="IQ_laplace_model.stan")
#fit stan model
laplace_stan_fit <- rstan::sampling(laplace_stan_model, data = list(N=n,a=a,b=b,mu0=mu0,k0=k0,y=y),refresh=0)
#extract samples
laplace_samples <- rstan::extract(laplace_stan_fit)
```

```{r}
set.seed(123)
laplace_mu_samples <- laplace_samples$mu
prob_laplace = sum((laplace_mu_samples > 100) == TRUE) / length(laplace_mu_samples)
prob_laplace
```

We have a higher posterior probability that the median IQ in the town is greater than 100 when using the Laplace model compared to the Normal model. This is due to the fact that the Laplace model is designed to add more weight to outlier values as opposed to the Normal Model. This would cause the median to be less affected by such outliers, leading to a larger posterior probability of an IQ greater than 100. Since the normal model does not adjust to account for outliers, the median value with the normal model would be shifted significantly lower, causing the posterior probability to be lower as well.

### Logistic regression for pesticide toxicity data.

A environmental agency is testing the effects of a pesticide that can cause acute poisoning in bees, the world's most important pollinator of food crops. The environmental agency collects data on exposure to different levels of the pestidicide in parts per million (ppm).  The agency also identifies collapsed beehives, which they expect could be due to acute pesticide poisoning.  In the data they collect, each observation is pair $(x_i, y_i)$, where $x_i$ represents the dosage of the pollutant and $y_i$ represents whether or not the hive survived.  Take $y_i=1$ means that the beehive has collapsed from poisoning and $y_i=0$ means the beehive survived.  The agency collects data at several different sites, each of which was exposed to a different dosages. The resulting data can be seen below:


```{r, echo=FALSE}
inv_logit <- function(x) { exp(x)/(1 + exp(x)) }
x <- round(runif(20, 1, 2), 2)
theta <- inv_logit(-5 + 4*x)
y <- rbinom(length(x), 1, theta)
```

```{r logistic_reg_setup}
x <- c(1.06, 1.41, 1.85, 1.5, 0.46, 1.21, 1.25, 1.09, 
       1.76, 1.75, 1.47, 1.03, 1.1, 1.41, 1.83, 1.17, 
       1.5, 1.64, 1.34, 1.31)
    
y <- c(0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 
       1, 0, 0, 1, 1, 0, 0, 1, 1, 0)
```

Assume that beehive collapse, $y_i$, given pollutant exposure level $x_i$, is $Y_i \sim \text{Bernoulli}(\theta(x_i))$, where $\theta(x_i)$ is the probability of death given dosage $x_i$.  We will assume that $\text{logit}(\theta_i(x_i)) = \alpha + \beta x_i$ where $\text{logit}(\theta)$ is defined as $\text{log}(\theta / (1-\theta))$. This model is known as _logistic regression_ and is one of the most common methods for modeling probabilities of binary events.  

**3a.** Solve for $\theta_i(x_i)$ as a function of $\alpha$ and $\beta$ by inverting the logit function.  If you haven't seen logistic regression before (it is covered in more detail in PSTAT 127 and PSTAT131), it is essentially a generalization of linear regression for binary outcomes. The inverse-logit function maps the linear part, $\alpha + \beta x_i$, which can be any real-valued number into the interval [0, 1] (since we are modeling probabilities of binary outcome, we need the mean outcome to be confined to this range).

$$log\left(\frac{\theta_i(x_i)}{1 - \theta_i(x_i)}\right) = \alpha + \beta x_i$$

$$\frac{\theta_i(x_i)}{1 - \theta_i(x_i)} = e^{\alpha + \beta x_i}$$

$$\theta_i(x_i) = e^{\alpha + \beta x_i}(1 - \theta_i(x_i))$$

$$\theta_i(x_i) = e^{\alpha + \beta x_i} - e^{\alpha + \beta x_i}\theta_i(x_i)$$

$$e^{\alpha + \beta x_i} = \theta_i(x_i) + e^{\alpha + \beta x_i}\theta_i(x_i)$$

$$e^{\alpha + \beta x_i} = \theta_i(x_i)(1 + e^{\alpha + \beta x_i})$$

$$\theta_i(x_i) = \frac{e^{\alpha + \beta x_i} }{1 + e^{\alpha + \beta x_i}}$$

We know this is correct as we have successfully inverted the logit function, as $inverselogit(x) = \frac{e^x}{1 + e^x}$.

**3b** The dose at which there is a 50\% chance of beehvive collapse, $\theta(x_i) = 0.5$, is known as LD50 ("letha dose 50%"), and is often of interest in toxicology studies.  Solve for LD50 as a function of $\alpha$ and $\beta$.  

$$0.5 = \frac{e^{\alpha + \beta x_i} }{1 + e^{\alpha + \beta x_i}}$$

$$0.5(1 + e^{\alpha + \beta x_i}) = e^{\alpha + \beta x_i}$$

$$0.5 + 0.5e^{\alpha + \beta x_i} = e^{\alpha + \beta x_i}$$

$$0.5 = e^{\alpha + \beta x_i} - 0.5e^{\alpha + \beta x_i}$$

$$0.5 = e^{\alpha + \beta x_i}(1 - 0.5)$$

$$e^{\alpha + \beta x_i} = \frac{0.5}{1-0.5}$$

$$e^{\alpha + \beta x_i} = 1$$

$$\alpha + \beta x_i = ln(1)$$

$$\alpha + \beta x_i = 0$$

$$x_i = -\frac{\alpha}{\beta} $$

**3c**  Implement the logistic regression model in stan by reproducing the stan model described here: [https://mc-stan.org/docs/2_18/stan-users-guide/logistic-probit-regression-section.html](https://mc-stan.org/docs/2_18/stan-users-guide/logistic-probit-regression-section.html).  Run the stan model on the beehive data to get Monte Carlo samples. Compute Monte Carlo samples of the LD50 by applying the function derived in the previous part to your $\alpha$ and $\beta$ samples. Report and estimate of the posterior mean of the LD50 by computing the sample average of all Monte Carlo samples of LD50.

```{r}
library(rstan)
x <- c(1.06, 1.41, 1.85, 1.5, 0.46, 1.21, 1.25, 1.09, 
       1.76, 1.75, 1.47, 1.03, 1.1, 1.41, 1.83, 1.17, 
       1.5, 1.64, 1.34, 1.31)
    
y <- c(0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 
       1, 0, 0, 1, 1, 0, 0, 1, 1, 0)

n = length(y)
#compile stan model
log_stan_model <- stan_model(file="logistic_model.stan")
#fit stan model
log_stan_fit <- rstan::sampling(log_stan_model, data = list(N=n,x=x, y=y),refresh=0)
#extract samples
log_samples <- rstan::extract(log_stan_fit)
```

```{r}
log_alpha_samples <- log_samples$alpha
log_beta_samples <- log_samples$beta

mean_ld50 = mean(-log_alpha_samples / log_beta_samples)
mean_ld50 
```

**3d**. Make a plot showing both 50\% and 95% confidence band for the probability of a hive collapse as a function of pollutant exposure, Pr($y=1 \mid \alpha, \beta, x)$.  Plot your data on a grid of x-values from $x = 0$ to $2$.  _Hint:_ see lab 7 for a similar example.

```{r logistic_reg, dependson="logistic_reg_setup", cache=TRUE}
set.seed(123)
xgrid <- seq(0, 2, by=0.1)

compute_curve <- function(sample) {
alpha <- sample[1]
beta <- sample[2]
y_values <- alpha + beta*xgrid
}
res <- apply(cbind(log_alpha_samples, log_beta_samples), 1, compute_curve)
#each col of res is for a set of alpha,beta values
#each row of res is different y values computed from different sets of alpha beta for a fixed x values.
quantiles <- apply(res, 1, function(x) quantile(x, c(0.025, 0.25, 0.75, 0.975)))
posterior_mean <- rowMeans(res)
posterior_mean <- apply(res, 1, median)
tibble(x=xgrid,
q025=quantiles[1, ],
q25=quantiles[2, ],
q75=quantiles[3, ],
q975=quantiles[4, ],
mean=posterior_mean) %>%
ggplot() +
geom_ribbon(aes(x=xgrid, ymin=q025, ymax=q975), alpha=0.2) +
geom_ribbon(aes(x=xgrid, ymin=q25, ymax=q75), alpha=0.5) +
geom_line(aes(x=xgrid, y=posterior_mean), size=1) +
theme_bw()
```

